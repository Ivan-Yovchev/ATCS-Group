{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('..')\n",
    "from preprocess import parse_debate_dataset, preprocess_hp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"]) \n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(labels, binary=False):\n",
    "    if not binary:\n",
    "        label_set = sorted(labels.unique())\n",
    "        preds = np.random.randint(label_set[0], high=label_set[-1]+1, size=len(labels))\n",
    "        return sum(preds == labels) / len(labels)\n",
    "    else:\n",
    "        return sum(labels) / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persuasiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df = parse_debate_dataset('./DebatePersuasiveness/DebateArguments.txt', nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(debates_df['Persuasiveness'], bins=6, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(debates_df['Persuasiveness'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.random.randint(1, high=7, size=len(debates_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_baseline(debates_df['Persuasiveness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_train = pd.read_json('DebatePersuasiveness/persuasiveness_dataset-train.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_valid = pd.read_json('DebatePersuasiveness/persuasiveness_dataset-valid.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_test = pd.read_json('DebatePersuasiveness/persuasiveness_dataset-test.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(debates_train['Persuasiveness'], bins=6, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(debates_valid['Persuasiveness'], bins=6, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(debates_test['Persuasiveness'], bins=6, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: samples {len(debates_train)}, baseline {get_baseline(debates_train[\"Persuasiveness\"]):.4f}')\n",
    "print(f'Valid: samples {len(debates_valid)}, baseline {get_baseline(debates_train[\"Persuasiveness\"]):.4f}')\n",
    "print(f'Test:  samples {len(debates_test)}, baseline {get_baseline(debates_train[\"Persuasiveness\"]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton_train = pd.read_csv('./GCDC/Clinton_train.csv')\n",
    "clinton_test  = pd.read_csv('./GCDC/Clinton_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clinton_train['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(clinton_test['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Clinton train baseline: {get_baseline(clinton_train[\"labelA\"])}')\n",
    "print(f'Clinton test  baseline: {get_baseline(clinton_test[\"labelA\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_train = pd.read_csv('./GCDC/Enron_train.csv')\n",
    "enron_test  = pd.read_csv('./GCDC/Enron_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(enron_train['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(enron_test['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Enron train baseline: {get_baseline(enron_train[\"labelA\"])}')\n",
    "print(f'Enron test  baseline: {get_baseline(enron_test[\"labelA\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_train = pd.read_csv('./GCDC/Yahoo_train.csv')\n",
    "yahoo_test  = pd.read_csv('./GCDC/Yahoo_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yahoo_train['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yahoo_test['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Yahoo train baseline: {get_baseline(yahoo_train[\"labelA\"])}')\n",
    "print(f'Yahoo test  baseline: {get_baseline(yahoo_test[\"labelA\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train = pd.read_csv('./GCDC/Yelp_train.csv')\n",
    "yelp_test  = pd.read_csv('./GCDC/Yelp_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yelp_train['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yelp_test['labelA'], bins=3, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Yelp train baseline: {get_baseline(yelp_train[\"labelA\"])}')\n",
    "print(f'Yelp test  baseline: {get_baseline(yelp_test[\"labelA\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperpartisan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_train = pd.read_json('./SemEval/byarticle-train.json', orient='records')\n",
    "hyper_valid = pd.read_json('./SemEval/byarticle-valid.json', orient='records')\n",
    "hyper_test = pd.read_json('./SemEval/byarticle-test.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_hyp = len(hyper_train)\n",
    "n_valid_hyp = len(hyper_valid)\n",
    "n_test_hyp  = len(hyper_test)\n",
    "n_train_hyp, n_valid_hyp, n_test_hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_train['label_int'] = hyper_train['label'].apply(lambda x: 1 if x == 'true' else 0)\n",
    "hyper_valid['label_int'] = hyper_valid['label'].apply(lambda x: 1 if x == 'true' else 0)\n",
    "hyper_test['label_int']  = hyper_test['label'].apply(lambda x: 1 if x == 'true' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_hyp = sum(hyper_train['label_int'])\n",
    "valid_pos_hyp = sum(hyper_valid['label_int'])\n",
    "test_pos_hyp  = sum(hyper_test['label_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: samples {n_train_hyp}, pos {train_pos_hyp}, baseline {get_baseline(hyper_train[\"label_int\"], binary=True):.4f}')\n",
    "print(f'Valid: samples {n_valid_hyp}, pos {valid_pos_hyp}, baseline {get_baseline(hyper_valid[\"label_int\"], binary=True):.4f}')\n",
    "print(f'Test:  samples {n_test_hyp}, pos {test_pos_hyp}, baseline {get_baseline(hyper_test[\"label_int\"], binary=True):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hyper_train['label_int'], bins=2, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hyper_valid['label_int'], bins=2, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hyper_test['label_int'], bins=2, edgecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News (Polit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_train = pd.read_csv('./FakeNews/politifact/train.tsv', sep='\\t', header=0, names=['text', 'label'])\n",
    "fake_news_valid = pd.read_csv('./FakeNews/politifact/val.tsv', sep='\\t', header=0, names=['text', 'label'])\n",
    "fake_news_test  = pd.read_csv('./FakeNews/politifact/test.tsv', sep='\\t', header=0, names=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_fake = len(fake_news_train)\n",
    "n_valid_fake = len(fake_news_valid)\n",
    "n_test_fake  = len(fake_news_test)\n",
    "n_train_fake, n_valid_fake, n_test_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_fake = sum(fake_news_train['label'])\n",
    "valid_pos_fake = sum(fake_news_valid['label'])\n",
    "test_pos_fake  = sum(fake_news_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: samples {n_train_fake}, pos {train_pos_fake}, baseline {get_baseline(fake_news_train[\"label\"], binary=True):.4f}')\n",
    "print(f'Valid: samples {n_valid_fake}, pos {valid_pos_fake}, baseline {get_baseline(fake_news_valid[\"label\"], binary=True):.4f}')\n",
    "print(f'Test:  samples {n_test_fake}, pos {test_pos_fake}, baseline {get_baseline(fake_news_test[\"label\"], binary=True):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fake_news_train['label'], bins=2, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fake_news_valid['label'], bins=2, edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fake_news_test['label'], bins=2,edgecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
